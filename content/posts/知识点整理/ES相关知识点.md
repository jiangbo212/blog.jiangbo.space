---
title: "ES相关知识点"
date: 2022-02-07T15:49:14+08:00
draft: false
categories: 知识点整理
keywords: ES Elastic 面试 索引 translog segment flush fsync Replica LogStash 倒排索引 页缓存 filesystem cache 分片式缓存 查询缓存
---
+ ### ES的基础概念
  
  1. Near Realtime(NRT) 近实时，ES是一个近实时的搜索服务。数据提交索引之后可以立即搜索到。为什么近实时可参考下文中的ES索引文档过程。

  2. Cluster 集群。一个集群由一个唯一的名字标识，默认为"elasticsearch".集群名称非常重要，具有相同集群名称的节点才能组成一个集群。集群名称在配置文件中指定。
  
  3. Node 节点。存储集群的数据，参与集群的索引和搜索功能。节点有自己的名称，启动时会以一个随机的UUID的前七个字符作为节点的名字，也可以指定任意的名字。通过集群名在网络中发现同伴组成集群。一个节点也可是集群。

  4. Index 索引。 一个索引是一个文档的集合。每个索引有唯一的名字，通过这个名字来操作它。一个集群中可以有任意多个索引。

  5. Type 类型。指在一个索引中，可以索引不同类型的文档，如用户数据、博客数据。从6.0.0 版本起已废弃，一个索引中只存放一类数据

  6. Document 文档。被索引的一条数据，索引的基本信息单元，以JSON格式来表示。

  7. Shard 分片。在创建一个索引时可以指定分成多少个分片来存储。每个分片本身也是一个功能完善且独立的“索引”，可以被放置在集群的任意节点上。Shard本质上是一个Lucene Index。

  8. Segments. Shard中包含了很多的Segments。ES的底层数据结构就保存在Segments中。比如，倒排索引(Inverted Index)， Stored Fields， Document Values， Cache。

  9.  Replication 备份: 一个分片可以有多个备份（副本）

+ ### ES的底层实现Luence, 倒排索引(Inverted Index)
  
  1. 一个有序的数据字典Dictionary（包括单词Term和它出现的频率）
   
  2. 与单词Term对应的Postings（即存在这个单词的文件）

+ ### ES中相应的缓存策略(主要参考[Elasticsearch 缓存深度剖析](https://www.elastic.co/cn/blog/elasticsearch-caching-deep-dive-boosting-query-speed-one-cache-at-a-time))

  1. 页缓存(filesystem cache, 磁盘缓存)
   
      页缓存属于操作系统级别的，即数据存储与内存中。ES在索引文档时，将segments存储与磁盘缓存；查询时，也许将相应信息及连带信息读入缓存，从而加快访问速度。这也就是为什么新写入的文档，查询过的文档及预热过的数据查询速度会提升的原因。因此，常见的ES配置，均将物理机对应的内存的一般分配给JVM，而将剩余的内存预留给页缓存。理论上将，内存越多，分配给页缓存的内存越多，ES的更多查询将经过内存，从而提升ES的查询数据。

  2. 分片级请求缓存
   
      通过缓存仅由聚合组成的搜索响应，这种缓存有助于加快 Kibana 的运行速度。这种缓存的理念是对请求的完整响应进行缓存，因此您根本不需要执行任何搜索，并且基本上可以立即返回响应。其实也就是缓存查询的整个结果，下次再进行的查询中如果覆盖了本次查询结果(包含了整个shard的文档)，那么就直接返回(此处应是直接在jvm中返回，不再进行搜索获取)。 

  3. 查询缓存
   
      查询缓存更精细些，可以缓存在不同查询之间重复使用的数据。它能够仅缓存查询的这一部分。基本理念是缓存信息而非搜索磁盘，并仅在那些已经缓存的文档中进行搜索您的查询

+ ### es索引文档过程

  1. es节点写入请求过程。write→refresh→flush→merge 

  2. es节点接受新的请求(写入数据)时，会首先将数据写入内存缓存，同时定时(默认1s)写入到磁盘的缓存区。以上过程称之为refresh。refresh后数据已经进入segment, 此时可以被搜索到。准实时的误差其实就是refresh的刷新时间。

  3. 特殊情况下，refresh过程中可能会存在丢失数据，这时候就需要es的translog机制。也就是在收到请求的同时写入到translog中。当磁盘缓存的数据写入到磁盘中时，translog会清除，这个过程为flush。flush的触发时机为定时出发(默认30分钟)或者translog变得太大时(默认512M)

  4. refresh过程中，每次会产生一个小的segment。由于是每秒刷新一次，过多的小的segment会影响系统性能，因此 es会不断的通过定时任务去合并小的segment。此过程可称之为merge。

+ ### es的translog机制
  
  flush过程中，内存中的缓存也会被清理，内容会被写入一个新段(segment), 段的fsync将创建一个新的提交点并将内容刷新到磁盘，旧的translog将被删除并重新开始一个新的translog。translog本质是一个日志文件，通过检查点来进行日志恢复。translog默认为每个请求时候进行一次fsync写入磁盘，这个可以强一致性的保证数据不丢失,但如此会影响性能. 如果对数据丢失有一定容忍，那么可以配置async，对其进行异步刷新。

+ ### es中的Replica(副本)机制
  
  es包含一个主分片及多个副本分片，由此来保证分布式。索引文档时，写入主片及多个副本分片(副本分片为并发写入)；读取时，只需其中一个返回即可返回结果。

+ ### ES常见的非常理情景
  
  1. 为什么添加文档时可能会导致存储空间的减少？

  答：ES在添加文档时，可能会合并过多的小的segments，从而导致空间占用的减少。

+ ### ES常见的合理利用场景
  
  1. 根据日期建立索引。常见使用场景为交易数据，日志数据。尤其是在需求在于根据日期查询的场景下。这样做的好处在于可以很快的拉取数据及删除过去数据。

+ ### LogStash。LogStash在ES的生态中基本是必不可少的。ES的数据一般不会直接写入，都是有第三方系统推送过来的。推送大部分情况下都是由LogStash来进行的。LogStash由如下几个好处：
  
  1. Logstash具有基于磁盘的自适应缓冲系统，该系统将吸收传入的吞吐量，从而减轻背压
   
  2. 从其他数据源（例如数据库，S3或消息传递队列）中提取
   
  3. 将数据发送到多个目的地，例如S3，HDFS或写入文件

  4. 使用条件数据流逻辑组成更复杂的处理管道

+ ### 